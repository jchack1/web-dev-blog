<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="https://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="http://localhost:4000/tag/aws/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2021-08-14T22:32:10-06:00</updated>
  <id>http://localhost:4000/tag/aws/feed.xml</id>

  
  
  

  
    <title type="html">Julia Hack | </title>
  

  
    <subtitle>Web development blog</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">How I lost, and regained, ssh access to my AWS EC2</title>
      <link href="http://localhost:4000/ec2-ssh" rel="alternate" type="text/html" title="How I lost, and regained, ssh access to my AWS EC2" />
      <published>2021-08-11T14:30:00-06:00</published>
      <updated>2021-08-11T14:30:00-06:00</updated>
      <id>http://localhost:4000/ec2-ssh</id>
      <content type="html" xml:base="http://localhost:4000/ec2-ssh">&lt;p&gt;This is a long story so I will leave out extra details to keep it (somewhat) brief.&lt;/p&gt;

&lt;p&gt;I was working with an AWS EC2 instance with wordpress installed. When you host your own wordpress sites, you need to keep up with server maintenance. I needed to update the PHP version for security reasons and I found a tutorial that told me to update ubuntu first. Once the update was complete, I no longer had ssh access to my EC2.&lt;/p&gt;

&lt;p&gt;After doing some reading, I believe this happened because there is some kind of a breaking change in the ssh config between ubuntu versions 16.04 and 18.04.&lt;/p&gt;

&lt;p&gt;For most users who have the physical device in front of them it is not difficult to run a few commands on their machine and repair the config issue. For me, however, my only access at the time was through ssh. I could not fix ssh and access the files on my machine until I had a command line or c-panel to work with.&lt;/p&gt;

&lt;p&gt;After a lot of trial an error I eventually regained access. I will share the process here.&lt;/p&gt;

&lt;h3 id=&quot;the-things-that-didnt-work&quot;&gt;The things that didn’t work&lt;/h3&gt;

&lt;p&gt;First I’ll list what I tried that &lt;em&gt;didn’t&lt;/em&gt; work. To be fair, though, it’s possible that some of these could work for someone else, as there is plenty of documentation for these methods.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;checked security groups to ensure ssh access still available on port 22 (it was)&lt;/li&gt;
  &lt;li&gt;added new security group with new port (1022) and try to ssh using it&lt;/li&gt;
  &lt;li&gt;created a &lt;em&gt;new&lt;/em&gt; AMI based on current EC2 instance, and launched an entirely new instance from it - still no ssh acces on new one&lt;/li&gt;
  &lt;li&gt;launched a new instance from an &lt;em&gt;old&lt;/em&gt; AMI that was created before I updated ubuntu&lt;/li&gt;
  &lt;li&gt;stopped the current instance, detached the EBS volume, reattached it, and restarted the instance&lt;/li&gt;
  &lt;li&gt;added user data script to restart ssh (method 4 in this article &lt;a href=&quot;https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-resolve-ssh-connection-errors/&quot;&gt;https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-resolve-ssh-connection-errors/&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;ran the troubleshoot ssh automation document (method 3 in this article &lt;a href=&quot;https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-resolve-ssh-connection-errors/&quot;&gt;https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-resolve-ssh-connection-errors/&lt;/a&gt;), hoping to find some clues as to the root of the problem&lt;/li&gt;
  &lt;li&gt;tried to set up EC2 connect - only works on nitro-based instances, and I wasn’t able to update my instance to a nitro-based system&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I was about ready to give up, but there was one more method I had not tried - setting up session manager&lt;/p&gt;

&lt;h3 id=&quot;the-session-manager-way&quot;&gt;The session manager way&lt;/h3&gt;

&lt;p&gt;While attempting all of the above processes I came across this option. There were a lot of steps in the documentation I read at that time and it seemed a bit intimidating to set up.&lt;/p&gt;

&lt;p&gt;I revisited it again while on the “connect” page in EC2. On this page there are tabs with several options to connect to your instance. Connecting via session manager was one of these options.&lt;/p&gt;

&lt;p&gt;I dismissed it earlier because it said I couldn’t connect. This time I paid attention to the possible reasons why the connection wasn’t being made. One possibility was that the proper IAM policy wasn’t attached, which could be added using &lt;a href=&quot;https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-sessions-start.html#start-ec2-console&quot;&gt;“quick set-up”&lt;/a&gt; in systems manager.&lt;/p&gt;

&lt;p&gt;So I gave it a try and followed along in the quick set-up console and chose an EC2 related configuration. When I returned to the EC2 connection session manager tab the warnings were gone.&lt;/p&gt;

&lt;p&gt;This time when I clicked “connect”, I got command line access to the EC2!&lt;/p&gt;

&lt;p&gt;Even when I ran the “pwd” linux command I was a bit lost in the file system. Signing in via session manager didn’t take me directly into the wordpress folders like it did on ssh login. Since now I could run commands I decided to troubleshoot ssh access once again.&lt;/p&gt;

&lt;p&gt;I tried a command to test ssh &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo sshd -t&lt;/code&gt; which unfortunatly didn’t provide anything useful for me.&lt;/p&gt;

&lt;p&gt;The information that I believe helped me the most was from &lt;a href=&quot;https://community.bitnami.com/t/ssh-stops-working-after-upgrade-to-ubuntu-18-04-on-aws-lightsail/64821/7&quot;&gt;this article on the bitnami community page&lt;/a&gt;, which addressed essentially the same problem I was having, just on AWS Lightsail. As Lightsail is built on EC2, I thought this might help.&lt;/p&gt;

&lt;p&gt;It suggested, as I suspected from earlier research, that the ssh config was the issue. They said to run these commands:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sudo sed -i 's/^Ciphers .*/Ciphers +aes256-cbc,aes192-cbc,aes128-cbc/' /etc/ssh/sshd_config
  sudo service sshd stop
  sudo service sshd start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I can’t say for sure these were the exact steps that solved my problem, since I ran some other commands around this time in session manager. But after running the above commands I tried to ssh into my instance again, and it worked. Mostly likely it was this attempt that fixed it since it’s the only one that addresses the config problem.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;This may be the most frustrating problem I’ve had to deal with yet in my dev journey. I’ve been stuck before many times but this was the closest I’ve been to running out of ideas and abandoning the project. Thankfully I was able to push through and that didn’t have to happen.&lt;/p&gt;

&lt;p&gt;The biggest benefit to working through this problem was that it forced me to dive deep into EC2. It helped to solidify my knowledge on EC2 and expose me to other AWS services. In addition, I learned more about linux systems, which was quite interesting for me since I don’t work with them often.&lt;/p&gt;

&lt;p&gt;If nothing else, this was a great learning opportunity. And I’m now very happy to move on.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="ec2" />
      
        <category term="linux" />
      
        <category term="debugging" />
      

      
        <summary type="html">This is a long story so I will leave out extra details to keep it (somewhat) brief.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AWS Lambda</title>
      <link href="http://localhost:4000/lambda" rel="alternate" type="text/html" title="AWS Lambda" />
      <published>2021-04-11T14:30:00-06:00</published>
      <updated>2021-04-11T14:30:00-06:00</updated>
      <id>http://localhost:4000/lambda</id>
      <content type="html" xml:base="http://localhost:4000/lambda">&lt;p&gt;AWS Lambda is huge for me at work. Our app architecture is primarily based on Lambda and the Serverless model.&lt;/p&gt;

&lt;p&gt;There are so many options to choose from when setting up your sevices with AWS. Until now in my Udemy course, a lot of what we have seen involves some sort of servers. A lot of time was spent talking about EC2s, which is basically a computer/server in the cloud that runs your apps.&lt;/p&gt;

&lt;p&gt;Apps created with Lambda don’t run on EC2. This is where “serverless” comes into play. Lambda functions are just functions, small pieces of code that have some purpose. You essentially deploy your lambda functions into AWS and everything is taken care of for you. Your functions can be “connected” by SNS, Eventbridge, SQS, etc (rather than having lambdas calling lambdas).&lt;/p&gt;

&lt;p&gt;We’ll go into more detail below. Once again I am taking notes from my Udemy course - “Ultimate AWS Certified Developer Associate 2021”.&lt;/p&gt;

&lt;h3 id=&quot;serverless&quot;&gt;Serverless&lt;/h3&gt;

&lt;p&gt;You only deploy your code/functions - you no longer have to manage and think about your servers.&lt;/p&gt;

&lt;p&gt;A typical serverless architecture in AWS could include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;users log in with Cognito&lt;/li&gt;
  &lt;li&gt;static site comes from S3&lt;/li&gt;
  &lt;li&gt;API Gateway accesses your Lambda functions, which access your DynamoDB database&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lambda&quot;&gt;Lambda&lt;/h3&gt;

&lt;p&gt;There is a time limit for your functions, up to 15 minutes. Lambda functions are run on demand, only invoked when you need them. They are scaled up automatically by AWS, so more functions are created when you need them. You only pay for invocations and compute time.&lt;/p&gt;

&lt;p&gt;This is different from EC2, which need to be running at all times, and provisioned by you to scale up or down in response to changes in traffic.&lt;/p&gt;

&lt;p&gt;API Gateway works well with Lambda - you create your REST API and the endpoints call your lambdas.&lt;/p&gt;

&lt;p&gt;When you invoke your function, you will get a new log stream in Cloudwatch. You can use Cloudwatch to help debug your functions.&lt;/p&gt;

&lt;h3 id=&quot;synchronous-invocation&quot;&gt;Synchronous invocation&lt;/h3&gt;

&lt;p&gt;You invoke the function, and you wait for the result. This can happen when you use API Gateway, the AWS SDK, or other services.&lt;/p&gt;

&lt;p&gt;Example: client calls API Gateway, which sends the request to Lambda. Lambda will run and return a response to the client through API Gateway. You wait for the response from the Lambda function.&lt;/p&gt;

&lt;h3 id=&quot;lambdas-and-albs-application-load-balancers&quot;&gt;Lambdas and ALBs (Application Load Balancers)&lt;/h3&gt;

&lt;p&gt;Another way, aside from API Gateway, to expose a lambda function via an HTTP endpoint. I first learned about ALBs through their use with EC2, but they can be used with lambdas as well.&lt;/p&gt;

&lt;p&gt;Lambda is registered to a target group. The HTTP request that is sent to the load balancer is converted to a JSON format. Once the lambda code runs, it should return a JSON object, which is converted to HTTP and sent back to the client to indicate the response.&lt;/p&gt;

&lt;p&gt;In a severless.yml file, you could set up ALBs with Lambdas like below, using an ALB event. This code is from &lt;a href=&quot;https://www.serverless.com/framework/docs/providers/aws/events/alb/&quot;&gt;serverless.com&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;functions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;albEventConsumer&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;handler&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;handler.hello&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;events&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;alb&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;listenerArn&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;arn:aws:elasticloadbalancing:us-east-1:12345:listener/app/my-load-balancer/50dc6c495c0c9188/&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;priority&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;conditions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/hello&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;asynchronous-invocations&quot;&gt;Asynchronous invocations&lt;/h3&gt;

&lt;p&gt;Events placed into event queue, lambda processes events. If there are problems processing, there are up to 3 retries. You can end up with your events processed multiple times. If processing continues to fail you can send the messages to a dead letter queue in SNS or SQS.&lt;/p&gt;

&lt;p&gt;S3, SNS, EventBridge, SES, CloudFormation all use asynchronous invocations.&lt;/p&gt;

&lt;p&gt;This can also be useful if you need to increase processing speed, and order/duplicates aren’t a big deal.&lt;/p&gt;

&lt;h3 id=&quot;eventbridge-and-lambda&quot;&gt;EventBridge and Lambda&lt;/h3&gt;

&lt;p&gt;2 ways to trigger lambda from EventBridge rule:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Set up CRON or Rate EventBridge rule (scheduled) - trigger lambda on a schedule, like every hour&lt;/li&gt;
  &lt;li&gt;Set up CodePipeline EventBridge Rule - trigger lambda whenever the state of the CodePipeline changes&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note: it wasn’t mentioned in the course, but at work we have services emitting EventBridge events that trigger our lambdas.&lt;/p&gt;

&lt;h3 id=&quot;iam-roles--permissions&quot;&gt;IAM Roles / permissions&lt;/h3&gt;

&lt;p&gt;When lambda functions are &lt;em&gt;invoking other services&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lambda functions need IAM roles attached to them so they have access to the AWS services they require. This is called an &lt;strong&gt;execution role&lt;/strong&gt;. You should have one execution role per lambda function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When lambdas are &lt;em&gt;being&lt;/em&gt; accessed by another service:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;give other services access to your lambdas by using a &lt;strong&gt;resource based policy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://www.serverless.com/blog/abcs-of-iam-permissions&quot;&gt;This link&lt;/a&gt; to serverless.com goes over how to work with IAM roles in serverless.&lt;/p&gt;

&lt;h3 id=&quot;environment-variables&quot;&gt;Environment variables&lt;/h3&gt;

&lt;p&gt;You can add and change environment variables in the Lambda console, but I tend to work with them only in the code.&lt;/p&gt;

&lt;p&gt;In serverless.yml files, variables look like this:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;variableA&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${variableSource}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#also can have a default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;variableB&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${variableSource, default}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#example, with a &quot;dev&quot; stage being the default&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;STAGE&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${opt:stage, 'dev'}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;networking&quot;&gt;Networking&lt;/h3&gt;

&lt;p&gt;By default, lambdas are launched in the AWS VPC, not your VPC, so they can’t access resources in your VPC. They can access other AWS services and external websites.&lt;/p&gt;

&lt;p&gt;You can launch them inside your VPC, though, and you need to set up the VPC ID, subnets, security groups, and an IAM role. You can deploy a lambda inside a private subnet with a NAT gateway if you want it to access the internet. Interestingly, putting it inside a &lt;em&gt;public&lt;/em&gt; subnet does not give it internet access, so you must use a private subnet.&lt;/p&gt;

&lt;h3 id=&quot;cloudformation&quot;&gt;Cloudformation&lt;/h3&gt;

&lt;p&gt;What I didn’t realize until now was that lambda function code is actually stored in S3. This isn’t something that you have to tell serverless to do explicitly - it is generated by serverless behind the scenes. If you look at the cloudformation templates that are generated by serverless, you will find references to S3 buckets in the code for your lambda functions.&lt;/p&gt;

&lt;p&gt;It looks something like this:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;S3Bucket&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ref&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ServerlessDeploymentBucket&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Under “Code” you could also write your code directly, but this is only good for very simple functions, and I honestly wouldn’t consider doing it. Instead you should just reference the S3 bucket where your code is stored.&lt;/p&gt;

&lt;p&gt;Here I can see just how useful serverless is. I don’t have to think about any of these things. In my serverless.yml file all I need to do is reference the handler that my lambda should correspond to with a file path.&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# here, my code is being kept in a folder called &quot;src&quot;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# this is all that's needed - serverless creates all other resources for me&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;createTeam&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;handler&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;src/teams/teams.createTeam&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In my course, in the Lambda/Cloudformation demo, the instructor is having to go into S3 in the AWS console and create a bucket. Then he needs to reference it in the cloudformation file.&lt;/p&gt;

&lt;p&gt;If you were to do this, you should enable versioning on your bucket (so new versions of your code are updated properly when deployed).&lt;/p&gt;

&lt;p&gt;Once your bucket is created, you upload your code, then go to the cloudformation console and upload your template. There is some config that needs to happen at this step.&lt;/p&gt;

&lt;p&gt;Definitely prefer serverless.yml files, uploaded from my machine, over this process.&lt;/p&gt;

&lt;h3 id=&quot;other-notes&quot;&gt;Other notes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Lambda can have up to 1000 concurrent executions at once. Lambdas scale up or down automatically. Important: this applies to all lambda functions across your account, not just one application, so you may want to set limits on your functions so one application doesn’t take up all your lambda resources.&lt;/li&gt;
  &lt;li&gt;when connecting to databases / creating other clients like the AWS SDK, it is best practice to initialize them outside of your handler functions at the top of your file. This makes them available for other functions, not just the current one.&lt;/li&gt;
  &lt;li&gt;Lambda layers: split up your function code and put reusable things like large libraries into separate layers - don’t have to be reuploaded every time you change your code, and other functions could use them as well.&lt;/li&gt;
  &lt;li&gt;can create different versions of your lambdas as well - your latest version is mutable, what you’re currently working on. Each version is immutable and can’t be changed once deployed
    &lt;ul&gt;
      &lt;li&gt;an alias is mutable and points to the latest version of your lambda&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="serverless" />
      

      
        <summary type="html">AWS Lambda is huge for me at work. Our app architecture is primarily based on Lambda and the Serverless model.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AWS SNS</title>
      <link href="http://localhost:4000/sns" rel="alternate" type="text/html" title="AWS SNS" />
      <published>2021-03-28T13:30:00-06:00</published>
      <updated>2021-03-28T13:30:00-06:00</updated>
      <id>http://localhost:4000/sns</id>
      <content type="html" xml:base="http://localhost:4000/sns">&lt;p&gt;Here is what I am learning about AWS SNS (Simple Notification Service), using my Udemy course as a jumping off point.&lt;/p&gt;

&lt;p&gt;I have already seen SNS to a small degree at work. I was tasked with creating alarms that would send notifications to our Slack channel if there were any errors in one of our services.&lt;/p&gt;

&lt;p&gt;You create SNS “topics” which store information about where notifications should be sent to. Other services “subscribe” to your SNS topics, so when triggered, a notification is sent to wherever you have indicated during set-up. In the case above, without going into too much extra detail, I created an SNS topic, which my alarm is subscribed to. When the alarm is triggered, the SNS topic sends information to our Slack channel.&lt;/p&gt;

&lt;p&gt;Let’s take a more detailed look at SNS. These are notes I have taken while going through the SNS section of my course.&lt;/p&gt;

&lt;h3 id=&quot;more-detail&quot;&gt;More detail&lt;/h3&gt;

&lt;p&gt;You can use SNS to send messages to &lt;strong&gt;many&lt;/strong&gt; different subscribers. One service sends a message to your SNS topic, which sends the message to all of the subscribers. This is an example of Pub/Sub or publish/subscribe pattern.&lt;/p&gt;

&lt;p&gt;For security, set IAM permissions and SNS Access Policies.&lt;/p&gt;

&lt;p&gt;If you set an email as a subscription, you will need to confirm the email address. You will get an email from AWS with a link to confirm subscription.&lt;/p&gt;

&lt;p&gt;If you want to test if your topic and subscriptions are working properly, go to the SNS console, click on your topic, and click the button “publish message”. Your subscribers should now receive a message.&lt;/p&gt;

&lt;h4 id=&quot;my-issues-setting-it-up-with-slack&quot;&gt;My issues setting it up with Slack&lt;/h4&gt;

&lt;p&gt;I should note, though, that when I set up our Slack channel with SNS (with AWS Chatbot as a subscriber), no messages were received in Slack when I tried “publish message”. I spent a lot of time going through my IAM policies, assuming it was a permissions error, but there was actually a better way to test if Chatbot was working. You had to try it out by creating an alarm in Cloudwatch and connecting it to the SNS topic. &lt;a href=&quot;https://docs.aws.amazon.com/chatbot/latest/adminguide/test-notifications-cw.html&quot;&gt;Here is the article that outlines this process&lt;/a&gt;. I still don’t know why it didn’t work to publish a message directly from SNS, but I’m grateful I found this article. Just test it out with an alarm!&lt;/p&gt;

&lt;h3 id=&quot;sns-and-sqs&quot;&gt;SNS and SQS&lt;/h3&gt;

&lt;p&gt;You can use both SNS and SQS at once. SNS can send messages to many different subscribers. You can have multiple SQS queues subscribed to SNS, and they all get the same message. This is called “fan-out”.&lt;/p&gt;

&lt;p&gt;NOTE: as of this writing, you can only send SNS messages to the &lt;strong&gt;standard&lt;/strong&gt; SQS queues, not FIFO.&lt;/p&gt;

&lt;p&gt;When this could be useful: S3 only allows one event rule, so if you want S3 to send message to multiple SQS queues, you could put SNS in between them. This way you send only one message to SNS, but it fans out to many SQS subscribers.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">Here is what I am learning about AWS SNS (Simple Notification Service), using my Udemy course as a jumping off point.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AWS SQS</title>
      <link href="http://localhost:4000/sqs" rel="alternate" type="text/html" title="AWS SQS" />
      <published>2021-03-22T18:30:00-06:00</published>
      <updated>2021-03-22T18:30:00-06:00</updated>
      <id>http://localhost:4000/sqs</id>
      <content type="html" xml:base="http://localhost:4000/sqs">&lt;p&gt;SQS is one of several AWS services that allows communication between your AWS resources. Today I am learning about it in my Udemy course. Here are some notes.&lt;/p&gt;

&lt;p&gt;SQS (Simple Queue Service) accepts messages from one microservice and delivers them to another. Your microservices do not communicate directly - this is asynchronous communication. SQS is able to scale up or down depending on traffic.&lt;/p&gt;

&lt;p&gt;A “producer” sends messages into an SQS queue, and “consumers” poll the queue for messages, essentially asking if the queue has any messages for it. Consumers are applications that run on an EC2, Lambda, or other servers, and they process the messages. In a standard queue you can send as many messages to your queue as you want, and you can keep unlimited messages in the queue as well. SQS is very quick, but messages need to be small (256 kb or smaller).&lt;/p&gt;

&lt;p&gt;Messages stay in the queue until the consumer reads and deletes it, up to 14 days.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Standard&lt;/strong&gt; SQS message delivery is “at least once” delivery, meaning your consumers may receive a message more than once. Order is also not guaranteed, as SQS uses a “best effort ordering” policy.&lt;/p&gt;

&lt;p&gt;This works nicely with auto-scaling groups/EC2 and Cloudwatch. You could set an alarm that watches the “queue length” metric, and when the alarm goes off, trigger your auto-scaling groups to increase the number of EC2 instances. In this case, your EC2s are your consumers, and you will have more of them to poll your SQS queue.&lt;/p&gt;

&lt;p&gt;Message visibility timeout: there is a 30 second window in which the consumer that got the message has to process it, before it becomes visible again to other consumers. During this 30 seconds the message is invisible to others. If the first consumer can’t process it in that window, other consumers will also be able to process it, so you may have the same message processed multiple times. You can have your consumer call the Change Message Visibility API to get more time for processing. It’s also possible to set visibility to something other than 30 seconds when setting up the queue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dead letter queue: &lt;/strong&gt; contains messages that have gone back into the queue multiple times. You can set a threshold for the maximum number of times a message goes back into the queue. Once the threshold is reached, the messages go to the dead letter queue. Another app can analyze these messages for debugging. Set the message retention period high, like to the 14 day maximum, for dead-letter queues.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Delay queue: &lt;/strong&gt; can delay messages for up to 15 minutes so consumer can’t see them right away&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Long polling: &lt;/strong&gt; consumers can wait for messages if none are currently in the queue. Means fewer API calls. Lower latency because a consumer can act on a message as soon as it comes into the queue. Preferable over short-polling since it reduces cost. In the console, add any number from 1 - 20 in the Receive Message Wait Time field while editing your queue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Extended client: &lt;/strong&gt; a Java library that uses an S3 bucket for large files, greater than the SQS 256kb limit. A small meta-data message goes into the queue, and it tells the consumer where to go in S3 to get the files.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First In First Out: &lt;/strong&gt; your other option instead of the standard queue. This queue preserves the order in which the messages are received by the queue. The consumer will receive them in order. It also has “exactly once” capability, so messages are only sent once.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;deduplication: do not allow messages into the queue if a duplicate is sent by the producer
    &lt;ul&gt;
      &lt;li&gt;content-based: SHA-265 algorithm creates a hash based on the content, and if that hash is seen by the queue again, it is not allowed&lt;/li&gt;
      &lt;li&gt;message duplication ID: an actual id that is provided with the message&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;message grouping: a group of messages has the same message group id, and only one consumer can accept the group of messages&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;using-sqs-with-serverless&quot;&gt;Using SQS with serverless&lt;/h3&gt;

&lt;p&gt;Since I work with serverless it’s important for me to understand how to create SQS quess with code, not just in the AWS console. Sometimes at work we use SQS with Lambda functions. The youtuber FooBarServerless thankfully has really great videos on serverless, and she happened to have a tutorial on using SQS with Lambda. Just what I need! &lt;a href=&quot;https://www.youtube.com/watch?v=hVdZb-h135M&quot;&gt;Here is the video&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, &lt;a href=&quot;https://www.serverless.com/framework/docs/providers/aws/events/sqs/&quot;&gt;here is the reference on serverless.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It’s best not to call a lambda from another lambda function. If you make changes to your lambda you could be in trouble. Putting something in between, like SQS in this case is helpful. You would have a lambda as the producer, and another as a consumer.&lt;/p&gt;

&lt;p&gt;When working with lambdas, you would first set up your SQS Queue as an AWS resources at the bottom of your file:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;Resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;MyQueue&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;AWS::SQS::Queue&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;QueueName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;DemoQueue&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And you connect your lambdas to the queue under the “events” section in your lambda code:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;mySqsFunction&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;handler&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;handler.mySqsFunction&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;events&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;sqs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;arn&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;Fn::GetAtt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MyDemoQueue&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Arn&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;batchSize&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Your actual function code is in a separate handler file.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">SQS is one of several AWS services that allows communication between your AWS resources. Today I am learning about it in my Udemy course. Here are some notes.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AWS Cloudformation - intrinsic functions</title>
      <link href="http://localhost:4000/cloudformation-intrinsic-functions" rel="alternate" type="text/html" title="AWS Cloudformation - intrinsic functions" />
      <published>2021-03-15T14:30:00-06:00</published>
      <updated>2021-03-15T14:30:00-06:00</updated>
      <id>http://localhost:4000/cloudformation-intrinsic-functions</id>
      <content type="html" xml:base="http://localhost:4000/cloudformation-intrinsic-functions">&lt;p&gt;AWS Cloudformation is a really great AWS service for creating “infrastructure as code”.&lt;/p&gt;

&lt;p&gt;If you have ever dabbled in AWS it’s possible that you have been creating your resources in the browser in the AWS console. I will say I enjoy creating my resources this way because I am a visual person and sometimes enjoy using a GUI. However, when working on real-world projects that involve other developers and AWS accounts and environments, it would become tedious to manually create these over and over again in the console. And it would be awful to have to re-create them in the case that they are accidentally deleted.&lt;/p&gt;

&lt;p&gt;Cloudformation allows you to create template files in YAML or JSON (I use YAML, I think this is most common) to declaratively create your AWS resources. The templates can be uploaded in the AWS console, or in the command line. For work I have my AWS credentials saved in a file on my computer, and I am able to deploy my templates from the command line. Despite what I said about enjoying using a GUI, once I got used to pushing code from the command line, that became my preference. It’s just so quick and easy once you get up and running. I imagine I’ll feel this way about Cloudformation with more experience.&lt;/p&gt;

&lt;p&gt;No surprise here but I am taking a course in AWS as well - Ultimate AWS Certified Developer Associate 2021 on Udemy. Some of the info here comes from that course as I work my way through the cloudformation section, as well as the AWS documentation.&lt;/p&gt;

&lt;h3 id=&quot;intrinsic-functions&quot;&gt;Intrinsic functions&lt;/h3&gt;

&lt;p&gt;As I was diving deeper into AWS Cloudformation I started to come across a lot of weird things I had never seen before while working with YAML. Things like !Ref, fn::GetAtt, etc. These are called &lt;strong&gt;intrinsic functions&lt;/strong&gt; and essentially allow you to make references to resouces and parameters inside your cloudformation template.&lt;/p&gt;

&lt;p&gt;First, a couple definitions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resources:&lt;/strong&gt; This is a required section in your template, which is where you declare the AWS resources that you want included in your stack. A resource is an AWS entity/service you can work with, like an EC2 instance, an SNS topic, or an S3 bucket.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; This is an optional section in your template. Parameters in a cloudformation template are like parameters you pass into a function. You define specific values for your parameters which can be referenced later on in your template. If you are referencing these parameters many times in your template, but you need to make a change, it is easier to change them once at the top of your file than have to update them several times throughout your code.&lt;/p&gt;

&lt;p&gt;When you see Fn::Something or !Something in the code you are dealing with an intrinsic function.&lt;/p&gt;

&lt;p&gt;Fn::Ref&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;in YAML code is !Ref&lt;/li&gt;
  &lt;li&gt;most common&lt;/li&gt;
  &lt;li&gt;can be used to reference a parameter - gives you the exact &lt;strong&gt;value&lt;/strong&gt; of the parameter&lt;/li&gt;
  &lt;li&gt;can be used to reference a resource - give you the &lt;strong&gt;physical ID&lt;/strong&gt; of the resource&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fn::GetAtt&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sometimes you need more than just the ID of a resource&lt;/li&gt;
  &lt;li&gt;attach to any resource, check docs to see the &lt;em&gt;attributes that are exposed&lt;/em&gt; by each type of resource&lt;/li&gt;
  &lt;li&gt;in YAML code it looks like this: !GetAtt MyInstance.AvailabilityZone&lt;/li&gt;
  &lt;li&gt;so, use !GetAtt, with the resource name, and the attribute you want&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fn::FindInMap&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;used similar to GetAtt, but to get a value out of a “Mapping” you made in your template&lt;/li&gt;
  &lt;li&gt;a “mapping” is where you hardcode values in your template that, for example, depend on what environment you’re in&lt;/li&gt;
  &lt;li&gt;maybe you are using a different image to create an EC2 instance based on what region you’re in, or whether you are in qa, dev, or prod environment. Hardcode these into your template and reference your map later on&lt;/li&gt;
  &lt;li&gt;in your code use like so: !FindInMap [MapName, TopLevelKey, SecondLevelKey]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fn::ImportValue&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to get values exported from another cloudformation template in its “Outputs” Section&lt;/li&gt;
  &lt;li&gt;your exports should have unique names across the region you’re working in&lt;/li&gt;
  &lt;li&gt;used in YAML code: !ImportValue ExportedResourceName&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fn::Join&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to join a list of values with a delimiter (a delimiter is a character that separates values - could be a comma, colon, etc)&lt;/li&gt;
  &lt;li&gt;!Join [delimiter, [list of values]]&lt;/li&gt;
  &lt;li&gt;puts the delimiter in between each value in the list&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fn::Sub&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to substitute a particular value with other values you specify&lt;/li&gt;
  &lt;li&gt;!Sub&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">AWS Cloudformation is a really great AWS service for creating “infrastructure as code”.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Deploying simple React app with Serverless / AWS</title>
      <link href="http://localhost:4000/deploy-react-serverless-aws" rel="alternate" type="text/html" title="Deploying simple React app with Serverless / AWS " />
      <published>2020-10-29T18:30:00-06:00</published>
      <updated>2020-10-29T18:30:00-06:00</updated>
      <id>http://localhost:4000/deploy-react-serverless-aws</id>
      <content type="html" xml:base="http://localhost:4000/deploy-react-serverless-aws">&lt;p&gt;I am learning Serverless and AWS for work. Here is what I did to deploy a basic app with Serverless.&lt;/p&gt;

&lt;p&gt;This is assuming you already have an AWS account, and have installed Serverless, the AWS SDK, and set up your AWS credentials on your machine.Simply put, though:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To install Serverless I ran this command: &lt;code class=&quot;highlighter-rouge&quot;&gt;npm i serverless -g&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;To install the AWS SDK I ran this command: &lt;code class=&quot;highlighter-rouge&quot;&gt;npm i aws-sdk -g&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Once you’ve set up an AWS account you can set up a new user in IAM, and save your credentials on your machine. &lt;a href=&quot;https://www.youtube.com/watch?v=w-OHgML58eg&amp;amp;t=1s&quot;&gt;This video shows that set-up&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this case I already had a project made, which I set up using &lt;code class=&quot;highlighter-rouge&quot;&gt;create-react-app&lt;/code&gt;. You can also set up a new serverless app by creating a new folder and running &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless create --template aws-nodejs&lt;/code&gt;. This is assuming you are using Node.js in the backend. There are many different runtimes you can use and templates available. You can also run &lt;code class=&quot;highlighter-rouge&quot;&gt;create-react-app&lt;/code&gt; after creating your serverless template. The order you do this doesn’t seem to matter, as long as you have all the files you need.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.serverless.com/framework/docs/providers/aws/guide/services/&quot;&gt;This article from Serverless explains services, and all associated files, very well&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To deploy static pages to an S3 bucket on AWS, I installed serverless-finch in my project using &lt;code class=&quot;highlighter-rouge&quot;&gt;npm i --save-dev serverless-finch&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When deploying a React app it is important to run the command &lt;code class=&quot;highlighter-rouge&quot;&gt;npm run build&lt;/code&gt;, so you get a build folder in your project directory. This is where all your static files end up including your index.html, which S3 needs to find in order to deploy your site.&lt;/p&gt;

&lt;h3 id=&quot;inside-the-serverlessyml-file&quot;&gt;Inside the serverless.yml file&lt;/h3&gt;

&lt;p&gt;Setting up a new serverless app will give you a handler file (in my case, handler.js), a .gitignore, and a serverless.yml file. serverless.yml is where you configure your service. Serverless uses this file to work with AWS to deploy your app.&lt;/p&gt;

&lt;p&gt;The following is what I have in my serverless.yml file:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;react-practice&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;provider&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;aws&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;${opt:stage, 'dev'}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;runtime&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nodejs12.x&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;us-west-2&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;functions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;handler&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;handler.hello&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#    The following are a few example events you can configure&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#    NOTE: Please make sure to change your handler code to work with those events&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#    Check the event documentation for details&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;events&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hello&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;get&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;serverless-finch&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;custom&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;bucketName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;julia-practice-react1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;distributionFolder&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/build&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;errorDocument&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.html&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;“service” essentially means project. It’s where you define all your functions, resources, events, plugins, and so on. Here you give the service a name.&lt;/p&gt;

&lt;p&gt;Under “provider” is where you specify that you are using AWS and configure your runtime, region, stage, etc. Stage refers to stage of development which includes development, QA, or production. Here the “dev” stage is default, if you don’t specify a stage when you deploy.&lt;/p&gt;

&lt;p&gt;Under each function you can have events. These are events that trigger the function to execute. In this example, and HTTP “get” request is triggering the “hello” function to execute.&lt;/p&gt;

&lt;p&gt;If you have a “resources” section, these are the resources that your functions use when they execute. These could include database tables.&lt;/p&gt;

&lt;p&gt;Note that under “plugins” I added “serverless-finch”.&lt;/p&gt;

&lt;p&gt;Under “custom” and “client” we configure S3.&lt;/p&gt;

&lt;p&gt;bucketName the bucket where S3 will place our files. It must be a globally unique name, meaning no one else in the world have have a bucket with this name.&lt;/p&gt;

&lt;p&gt;distributionFolder is where S3 should look for our files. For React we use “/build”, since that’s where our index.html is.&lt;/p&gt;

&lt;p&gt;S3 also requires you have an errorDocument specified. Since this is just a simple app I didn’t make one and just left it as index.html.&lt;/p&gt;

&lt;h4 id=&quot;what-serverless-does-with-the-serverlessyml-file&quot;&gt;What Serverless does with the serverless.yml file&lt;/h4&gt;

&lt;p&gt;Serverless takes the serverless.yml file and translates it into an AWS CloudFormation template.&lt;/p&gt;

&lt;p&gt;CloudFormation is an AWS service that allows you to manage all your AWS services/resources. You would write a template describing everything you want, and CloudFormation configures it for you.&lt;/p&gt;

&lt;p&gt;This sounds like an improvement over configuring everything yourself in the AWS management console, though these files can still get pretty long and take time to create. That’s where Serverless comes in. Serverless takes your serverless.yml file and creates CloudFormation templates for you.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.serverless.com/framework/docs/providers/aws/guide/deploying/&quot;&gt;Here’s an article describing deployment with Serverless&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;deployment&quot;&gt;Deployment&lt;/h3&gt;

&lt;p&gt;Note: you can set up different commands in the “scripts” section of your package.json file.&lt;/p&gt;

&lt;p&gt;For backend stuff, especially for Lambda functions, run &lt;code class=&quot;highlighter-rouge&quot;&gt;sls deploy --aws-profile={whatever name you set up in your aws credentials file}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To deploy the client side, into your S3 bucket, run this command &lt;code class=&quot;highlighter-rouge&quot;&gt;sls client deploy --aws-profile={whatever name you set up in your aws credentials file}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Your screen should look something like this if successful. You will see a link you can go to and view the site.
&lt;img src=&quot;../assets/images/sls-cli.jpg&quot; style=&quot;max-width: 500px;&quot; alt=&quot;serverless cli successful&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;errors&quot;&gt;Errors&lt;/h3&gt;

&lt;p&gt;I got an error reading “Serverless Error: Access Denied”. This seemed strange because I never got this error for the backend deploy, so I thought it must have to do with S3. I fixed this by making my bucket public, but I don’t think this is very secure so I need to look into this further.&lt;/p&gt;

&lt;p&gt;Another error said that I was not in the correct region. This was because my bucket and my serverless.yml file “region” did not match. I just had to quickly update my .yml file and there error was solved. I could now see my site.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="react" />
      
        <category term="aws" />
      
        <category term="serverless" />
      

      
        <summary type="html">I am learning Serverless and AWS for work. Here is what I did to deploy a basic app with Serverless.</summary>
      

      
      
    </entry>
  
</feed>
